{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1263fd21",
   "metadata": {},
   "source": [
    "# Neptune Technologies Job Application form Screening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c4725d",
   "metadata": {},
   "source": [
    "##### Importing neccessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc2816cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # to perform tasks like reading file names from directories and managing file paths.\n",
    "import re # to enable pattern matching and manipulation of text strings using regular expressions\n",
    "import nltk # for natural language processing tasks\n",
    "from nltk.corpus import stopwords # Stopwords consist of articles, prepositions, and conjunctions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6da786",
   "metadata": {},
   "source": [
    "### Importing resume, cover letter and form data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d930811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing applicant's resume file\n",
    "resume_filepath = \"C:\\\\Users\\\\akunna1\\\\Desktop\\\\Projects\\\\Project_3\\\\project_directory\\\\GC_Downloads_txt\\\\john_doe_resume.txt\"\n",
    "#change for each applicant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "235edf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing applicant's cover letter file\n",
    "cover_letter_filepath = \"C:\\\\Users\\\\akunna1\\\\Desktop\\\\Projects\\\\Project_3\\\\project_directory\\\\GC_Downloads_txt\\\\john_doe_cover_letter.txt\"\n",
    "#change for each applicant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1df5ffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing applicant's form data file\n",
    "form_data_filepath = \"C:\\\\Users\\\\akunna1\\\\Desktop\\\\Projects\\\\Project_3\\\\project_directory\\\\GC_Downloads_txt\\\\john_doe_form.txt\"\n",
    "#change for each applicant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa08316",
   "metadata": {},
   "source": [
    "### Resume Analysis and Grading Section (40%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d0d3aa",
   "metadata": {},
   "source": [
    "##### Removing StopWords, Numerical Digits, Punctuations, Symbols, Extra Spaces, Making Text lowercase and Normalizing and Tokenizing the Text from Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd56d513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Adding auxiliary verbs to the stopwords list\n",
    "auxiliary_verbs = ['am', 'is', 'are', 'was', 'were', 'be', 'been', 'being',\n",
    "                   'have', 'has', 'had', 'do', 'does', 'did', 'can', 'could',\n",
    "                   'shall', 'should', 'will', 'would', 'may', 'might', 'must']\n",
    "\n",
    "stop_words.update(auxiliary_verbs)\n",
    "\n",
    "# Initializing a list to store the processed resume\n",
    "processed_resume = []\n",
    "\n",
    "# Opening and reading the original file\n",
    "with open(resume_filepath, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        review_text = line.strip()\n",
    "        \n",
    "        # Text cleaning and normalization\n",
    "        for punctuations_and_more in ['●','–', ',', '.', '\"', '!', '?', ':', ';', '-', '(', ')', '[', ']', \"'\", '*', '$', '/', '+','’', \n",
    "                             '_','|','@']:\n",
    "            review_text = review_text.replace(punctuations_and_more, ' ')  # Replacing punctuations with spaces\n",
    "            review_text = re.sub('\\s+', ' ', review_text)  # Removing extra spaces\n",
    "            review_text = review_text.lower().strip()  # Making text lowercase\n",
    "\n",
    "        # Removing numerical digits\n",
    "        review_text = re.sub(r'\\d', '', review_text)\n",
    "        \n",
    "        # Tokenizing the cleaned review text\n",
    "        words = nltk.word_tokenize(review_text)\n",
    "        \n",
    "        # Removing stopwords, including auxiliary verbs\n",
    "        filtered_words = [word for word in words if word not in stop_words]\n",
    "        \n",
    "        # Joining the filtered words back into a sentence\n",
    "        processed_resume_x = ' '.join(filtered_words)\n",
    "        \n",
    "        processed_resume.append(processed_resume_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "343ef186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['john doe', 'software engineer', 'www johndoe com johndoe gmail com', 'linkedin', 'github', '', 'technical skills', 'technologies ruby rails activerecord postgresql rspec capybara html heroku travisci graphql', 'practices object oriented programming test driven development agile development restful design git version control continuous', 'integration mvc architecture json construction consumption', '', 'experience', 'backend software engineering student', '', 'turing school software design', '', 'investment hours creating projects range basic ruby database backend rails applications well rest api built', 'using test driven development following object oriented design principles', '', 'student success mentor help current students understand concepts surrounding ruby rails postgresql oop ttd many', 'technical topics', '', 'senior surgical neurophysiologist cnim', '', 'assure neuromonitoring national technologist', '', 'part two member team tasked establishing advanced neuromonitoring procedures brain tumor removal surgeries', 'culicchia neurological clinic new orleans', '', 'personally trained surgical neurophysiologists hospitals nationwide neuromonitoring protocols various advanced procedures', '', 'traveled surgery centers hospitals nationwide consult establish neuromonitoring procedures various surgeries', '', 'surgical neurophysiologist cnim', '', 'nuvasive clinical services mayo clinic team lead', '', 'lead surgical neurophysiologist various complex neuromonitoring procedures including brain aneurysm surgeries complex multilevel spine', 'surgeries patient asleep patient awake brain tumor removal surgeries', '', 'worked chief neurosurgery dr quinones neurosurgery team provide cortical mapping eeg neuromonitoring', 'patient awake brain tumor removal surgeries', '', 'implemented training regimen associate level surgical neurophysiologists transition advanced brain vascular surgeries', '', 'projects', 'saturn earth github production', 'group full stack project allowing users create posts gain ‘ likes order viewed users based location', 'created graphql api frontend team successfully implemented backend geolocation features', 'tech ruby rails postgresql heroku graphql rspec capybara', 'sweater weather api github production', 'creation rest api aggregate data well provide crud functionality', 'solo greenfield project utilize openweather mapquest pexel api', 'tech ruby rails postgresql heroku rspec capybara', 'monster shop github production', 'creation database backed e commerce application full crud functionality', 'successfully implemented stretch goal feature automatically apply discounts items checkout', 'tech ruby rails rspec capybara postgresql heroku', '', 'education', 'backend software engineering turing school software design', '', 'b sc biological health science university south florida', '']\n"
     ]
    }
   ],
   "source": [
    "# Displaying processed_resume\n",
    "print(processed_resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98e2ea0",
   "metadata": {},
   "source": [
    "##### Combining all lines in processed_resume into a single line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7329156e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "john doe software engineer www johndoe com johndoe gmail com linkedin github  technical skills technologies ruby rails activerecord postgresql rspec capybara html heroku travisci graphql practices object oriented programming test driven development agile development restful design git version control continuous integration mvc architecture json construction consumption  experience backend software engineering student  turing school software design  investment hours creating projects range basic ruby database backend rails applications well rest api built using test driven development following object oriented design principles  student success mentor help current students understand concepts surrounding ruby rails postgresql oop ttd many technical topics  senior surgical neurophysiologist cnim  assure neuromonitoring national technologist  part two member team tasked establishing advanced neuromonitoring procedures brain tumor removal surgeries culicchia neurological clinic new orleans  personally trained surgical neurophysiologists hospitals nationwide neuromonitoring protocols various advanced procedures  traveled surgery centers hospitals nationwide consult establish neuromonitoring procedures various surgeries  surgical neurophysiologist cnim  nuvasive clinical services mayo clinic team lead  lead surgical neurophysiologist various complex neuromonitoring procedures including brain aneurysm surgeries complex multilevel spine surgeries patient asleep patient awake brain tumor removal surgeries  worked chief neurosurgery dr quinones neurosurgery team provide cortical mapping eeg neuromonitoring patient awake brain tumor removal surgeries  implemented training regimen associate level surgical neurophysiologists transition advanced brain vascular surgeries  projects saturn earth github production group full stack project allowing users create posts gain ‘ likes order viewed users based location created graphql api frontend team successfully implemented backend geolocation features tech ruby rails postgresql heroku graphql rspec capybara sweater weather api github production creation rest api aggregate data well provide crud functionality solo greenfield project utilize openweather mapquest pexel api tech ruby rails postgresql heroku rspec capybara monster shop github production creation database backed e commerce application full crud functionality successfully implemented stretch goal feature automatically apply discounts items checkout tech ruby rails rspec capybara postgresql heroku  education backend software engineering turing school software design  b sc biological health science university south florida \n"
     ]
    }
   ],
   "source": [
    "concatenated_resume = ' '.join(processed_resume)\n",
    "print(concatenated_resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78827735",
   "metadata": {},
   "source": [
    "##### Word Pairs Calculation for Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9a2f49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4mAll the Word Pairs:\u001b[0m\n",
      "These word pairs: ('ruby', 'rails') appeared 5 times\n",
      "These word pairs: ('rspec', 'capybara') appeared 4 times\n",
      "These word pairs: ('rails', 'postgresql') appeared 3 times\n",
      "These word pairs: ('surgical', 'neurophysiologist') appeared 3 times\n",
      "These word pairs: ('neuromonitoring', 'procedures') appeared 3 times\n",
      "These word pairs: ('brain', 'tumor') appeared 3 times\n",
      "These word pairs: ('tumor', 'removal') appeared 3 times\n",
      "These word pairs: ('removal', 'surgeries') appeared 3 times\n",
      "These word pairs: ('github', 'production') appeared 3 times\n",
      "These word pairs: ('tech', 'ruby') appeared 3 times\n",
      "These word pairs: ('postgresql', 'heroku') appeared 3 times\n",
      "These word pairs: ('object', 'oriented') appeared 2 times\n",
      "These word pairs: ('test', 'driven') appeared 2 times\n",
      "These word pairs: ('driven', 'development') appeared 2 times\n",
      "These word pairs: ('backend', 'software') appeared 2 times\n",
      "These word pairs: ('software', 'engineering') appeared 2 times\n",
      "These word pairs: ('turing', 'school') appeared 2 times\n",
      "These word pairs: ('school', 'software') appeared 2 times\n",
      "These word pairs: ('software', 'design') appeared 2 times\n",
      "These word pairs: ('rest', 'api') appeared 2 times\n",
      "These word pairs: ('neurophysiologist', 'cnim') appeared 2 times\n",
      "These word pairs: ('surgical', 'neurophysiologists') appeared 2 times\n",
      "These word pairs: ('hospitals', 'nationwide') appeared 2 times\n",
      "These word pairs: ('patient', 'awake') appeared 2 times\n",
      "These word pairs: ('awake', 'brain') appeared 2 times\n",
      "These word pairs: ('successfully', 'implemented') appeared 2 times\n",
      "These word pairs: ('production', 'creation') appeared 2 times\n",
      "These word pairs: ('crud', 'functionality') appeared 2 times\n",
      "These word pairs: ('john', 'doe') appeared 1 times\n",
      "These word pairs: ('doe', 'software') appeared 1 times\n",
      "These word pairs: ('software', 'engineer') appeared 1 times\n",
      "These word pairs: ('engineer', 'www') appeared 1 times\n",
      "These word pairs: ('www', 'johndoe') appeared 1 times\n",
      "These word pairs: ('johndoe', 'com') appeared 1 times\n",
      "These word pairs: ('com', 'johndoe') appeared 1 times\n",
      "These word pairs: ('johndoe', 'gmail') appeared 1 times\n",
      "These word pairs: ('gmail', 'com') appeared 1 times\n",
      "These word pairs: ('com', 'linkedin') appeared 1 times\n",
      "These word pairs: ('linkedin', 'github') appeared 1 times\n",
      "These word pairs: ('github', 'technical') appeared 1 times\n",
      "These word pairs: ('technical', 'skills') appeared 1 times\n",
      "These word pairs: ('skills', 'technologies') appeared 1 times\n",
      "These word pairs: ('technologies', 'ruby') appeared 1 times\n",
      "These word pairs: ('rails', 'activerecord') appeared 1 times\n",
      "These word pairs: ('activerecord', 'postgresql') appeared 1 times\n",
      "These word pairs: ('postgresql', 'rspec') appeared 1 times\n",
      "These word pairs: ('capybara', 'html') appeared 1 times\n",
      "These word pairs: ('html', 'heroku') appeared 1 times\n",
      "These word pairs: ('heroku', 'travisci') appeared 1 times\n",
      "These word pairs: ('travisci', 'graphql') appeared 1 times\n",
      "These word pairs: ('graphql', 'practices') appeared 1 times\n",
      "These word pairs: ('practices', 'object') appeared 1 times\n",
      "These word pairs: ('oriented', 'programming') appeared 1 times\n",
      "These word pairs: ('programming', 'test') appeared 1 times\n",
      "These word pairs: ('development', 'agile') appeared 1 times\n",
      "These word pairs: ('agile', 'development') appeared 1 times\n",
      "These word pairs: ('development', 'restful') appeared 1 times\n",
      "These word pairs: ('restful', 'design') appeared 1 times\n",
      "These word pairs: ('design', 'git') appeared 1 times\n",
      "These word pairs: ('git', 'version') appeared 1 times\n",
      "These word pairs: ('version', 'control') appeared 1 times\n",
      "These word pairs: ('control', 'continuous') appeared 1 times\n",
      "These word pairs: ('continuous', 'integration') appeared 1 times\n",
      "These word pairs: ('integration', 'mvc') appeared 1 times\n",
      "These word pairs: ('mvc', 'architecture') appeared 1 times\n",
      "These word pairs: ('architecture', 'json') appeared 1 times\n",
      "These word pairs: ('json', 'construction') appeared 1 times\n",
      "These word pairs: ('construction', 'consumption') appeared 1 times\n",
      "These word pairs: ('consumption', 'experience') appeared 1 times\n",
      "These word pairs: ('experience', 'backend') appeared 1 times\n",
      "These word pairs: ('engineering', 'student') appeared 1 times\n",
      "These word pairs: ('student', 'turing') appeared 1 times\n",
      "These word pairs: ('design', 'investment') appeared 1 times\n",
      "These word pairs: ('investment', 'hours') appeared 1 times\n",
      "These word pairs: ('hours', 'creating') appeared 1 times\n",
      "These word pairs: ('creating', 'projects') appeared 1 times\n",
      "These word pairs: ('projects', 'range') appeared 1 times\n",
      "These word pairs: ('range', 'basic') appeared 1 times\n",
      "These word pairs: ('basic', 'ruby') appeared 1 times\n",
      "These word pairs: ('ruby', 'database') appeared 1 times\n",
      "These word pairs: ('database', 'backend') appeared 1 times\n",
      "These word pairs: ('backend', 'rails') appeared 1 times\n",
      "These word pairs: ('rails', 'applications') appeared 1 times\n",
      "These word pairs: ('applications', 'well') appeared 1 times\n",
      "These word pairs: ('well', 'rest') appeared 1 times\n",
      "These word pairs: ('api', 'built') appeared 1 times\n",
      "These word pairs: ('built', 'using') appeared 1 times\n",
      "These word pairs: ('using', 'test') appeared 1 times\n",
      "These word pairs: ('development', 'following') appeared 1 times\n",
      "These word pairs: ('following', 'object') appeared 1 times\n",
      "These word pairs: ('oriented', 'design') appeared 1 times\n",
      "These word pairs: ('design', 'principles') appeared 1 times\n",
      "These word pairs: ('principles', 'student') appeared 1 times\n",
      "These word pairs: ('student', 'success') appeared 1 times\n",
      "These word pairs: ('success', 'mentor') appeared 1 times\n",
      "These word pairs: ('mentor', 'help') appeared 1 times\n",
      "These word pairs: ('help', 'current') appeared 1 times\n",
      "These word pairs: ('current', 'students') appeared 1 times\n",
      "These word pairs: ('students', 'understand') appeared 1 times\n",
      "These word pairs: ('understand', 'concepts') appeared 1 times\n",
      "These word pairs: ('concepts', 'surrounding') appeared 1 times\n",
      "These word pairs: ('surrounding', 'ruby') appeared 1 times\n",
      "These word pairs: ('postgresql', 'oop') appeared 1 times\n",
      "These word pairs: ('oop', 'ttd') appeared 1 times\n",
      "These word pairs: ('ttd', 'many') appeared 1 times\n",
      "These word pairs: ('many', 'technical') appeared 1 times\n",
      "These word pairs: ('technical', 'topics') appeared 1 times\n",
      "These word pairs: ('topics', 'senior') appeared 1 times\n",
      "These word pairs: ('senior', 'surgical') appeared 1 times\n",
      "These word pairs: ('cnim', 'assure') appeared 1 times\n",
      "These word pairs: ('assure', 'neuromonitoring') appeared 1 times\n",
      "These word pairs: ('neuromonitoring', 'national') appeared 1 times\n",
      "These word pairs: ('national', 'technologist') appeared 1 times\n",
      "These word pairs: ('technologist', 'part') appeared 1 times\n",
      "These word pairs: ('part', 'two') appeared 1 times\n",
      "These word pairs: ('two', 'member') appeared 1 times\n",
      "These word pairs: ('member', 'team') appeared 1 times\n",
      "These word pairs: ('team', 'tasked') appeared 1 times\n",
      "These word pairs: ('tasked', 'establishing') appeared 1 times\n",
      "These word pairs: ('establishing', 'advanced') appeared 1 times\n",
      "These word pairs: ('advanced', 'neuromonitoring') appeared 1 times\n",
      "These word pairs: ('procedures', 'brain') appeared 1 times\n",
      "These word pairs: ('surgeries', 'culicchia') appeared 1 times\n",
      "These word pairs: ('culicchia', 'neurological') appeared 1 times\n",
      "These word pairs: ('neurological', 'clinic') appeared 1 times\n",
      "These word pairs: ('clinic', 'new') appeared 1 times\n",
      "These word pairs: ('new', 'orleans') appeared 1 times\n",
      "These word pairs: ('orleans', 'personally') appeared 1 times\n",
      "These word pairs: ('personally', 'trained') appeared 1 times\n",
      "These word pairs: ('trained', 'surgical') appeared 1 times\n",
      "These word pairs: ('neurophysiologists', 'hospitals') appeared 1 times\n",
      "These word pairs: ('nationwide', 'neuromonitoring') appeared 1 times\n",
      "These word pairs: ('neuromonitoring', 'protocols') appeared 1 times\n",
      "These word pairs: ('protocols', 'various') appeared 1 times\n",
      "These word pairs: ('various', 'advanced') appeared 1 times\n",
      "These word pairs: ('advanced', 'procedures') appeared 1 times\n",
      "These word pairs: ('procedures', 'traveled') appeared 1 times\n",
      "These word pairs: ('traveled', 'surgery') appeared 1 times\n",
      "These word pairs: ('surgery', 'centers') appeared 1 times\n",
      "These word pairs: ('centers', 'hospitals') appeared 1 times\n",
      "These word pairs: ('nationwide', 'consult') appeared 1 times\n",
      "These word pairs: ('consult', 'establish') appeared 1 times\n",
      "These word pairs: ('establish', 'neuromonitoring') appeared 1 times\n",
      "These word pairs: ('procedures', 'various') appeared 1 times\n",
      "These word pairs: ('various', 'surgeries') appeared 1 times\n",
      "These word pairs: ('surgeries', 'surgical') appeared 1 times\n",
      "These word pairs: ('cnim', 'nuvasive') appeared 1 times\n",
      "These word pairs: ('nuvasive', 'clinical') appeared 1 times\n",
      "These word pairs: ('clinical', 'services') appeared 1 times\n",
      "These word pairs: ('services', 'mayo') appeared 1 times\n",
      "These word pairs: ('mayo', 'clinic') appeared 1 times\n",
      "These word pairs: ('clinic', 'team') appeared 1 times\n",
      "These word pairs: ('team', 'lead') appeared 1 times\n",
      "These word pairs: ('lead', 'surgical') appeared 1 times\n",
      "These word pairs: ('neurophysiologist', 'various') appeared 1 times\n",
      "These word pairs: ('various', 'complex') appeared 1 times\n",
      "These word pairs: ('complex', 'neuromonitoring') appeared 1 times\n",
      "These word pairs: ('procedures', 'including') appeared 1 times\n",
      "These word pairs: ('including', 'brain') appeared 1 times\n",
      "These word pairs: ('brain', 'aneurysm') appeared 1 times\n",
      "These word pairs: ('aneurysm', 'surgeries') appeared 1 times\n",
      "These word pairs: ('surgeries', 'complex') appeared 1 times\n",
      "These word pairs: ('complex', 'multilevel') appeared 1 times\n",
      "These word pairs: ('multilevel', 'spine') appeared 1 times\n",
      "These word pairs: ('spine', 'surgeries') appeared 1 times\n",
      "These word pairs: ('surgeries', 'patient') appeared 1 times\n",
      "These word pairs: ('patient', 'asleep') appeared 1 times\n",
      "These word pairs: ('asleep', 'patient') appeared 1 times\n",
      "These word pairs: ('surgeries', 'worked') appeared 1 times\n",
      "These word pairs: ('worked', 'chief') appeared 1 times\n",
      "These word pairs: ('chief', 'neurosurgery') appeared 1 times\n",
      "These word pairs: ('neurosurgery', 'dr') appeared 1 times\n",
      "These word pairs: ('dr', 'quinones') appeared 1 times\n",
      "These word pairs: ('quinones', 'neurosurgery') appeared 1 times\n",
      "These word pairs: ('neurosurgery', 'team') appeared 1 times\n",
      "These word pairs: ('team', 'provide') appeared 1 times\n",
      "These word pairs: ('provide', 'cortical') appeared 1 times\n",
      "These word pairs: ('cortical', 'mapping') appeared 1 times\n",
      "These word pairs: ('mapping', 'eeg') appeared 1 times\n",
      "These word pairs: ('eeg', 'neuromonitoring') appeared 1 times\n",
      "These word pairs: ('neuromonitoring', 'patient') appeared 1 times\n",
      "These word pairs: ('surgeries', 'implemented') appeared 1 times\n",
      "These word pairs: ('implemented', 'training') appeared 1 times\n",
      "These word pairs: ('training', 'regimen') appeared 1 times\n",
      "These word pairs: ('regimen', 'associate') appeared 1 times\n",
      "These word pairs: ('associate', 'level') appeared 1 times\n",
      "These word pairs: ('level', 'surgical') appeared 1 times\n",
      "These word pairs: ('neurophysiologists', 'transition') appeared 1 times\n",
      "These word pairs: ('transition', 'advanced') appeared 1 times\n",
      "These word pairs: ('advanced', 'brain') appeared 1 times\n",
      "These word pairs: ('brain', 'vascular') appeared 1 times\n",
      "These word pairs: ('vascular', 'surgeries') appeared 1 times\n",
      "These word pairs: ('surgeries', 'projects') appeared 1 times\n",
      "These word pairs: ('projects', 'saturn') appeared 1 times\n",
      "These word pairs: ('saturn', 'earth') appeared 1 times\n",
      "These word pairs: ('earth', 'github') appeared 1 times\n",
      "These word pairs: ('production', 'group') appeared 1 times\n",
      "These word pairs: ('group', 'full') appeared 1 times\n",
      "These word pairs: ('full', 'stack') appeared 1 times\n",
      "These word pairs: ('stack', 'project') appeared 1 times\n",
      "These word pairs: ('project', 'allowing') appeared 1 times\n",
      "These word pairs: ('allowing', 'users') appeared 1 times\n",
      "These word pairs: ('users', 'create') appeared 1 times\n",
      "These word pairs: ('create', 'posts') appeared 1 times\n",
      "These word pairs: ('posts', 'gain') appeared 1 times\n",
      "These word pairs: ('gain', '‘') appeared 1 times\n",
      "These word pairs: ('‘', 'likes') appeared 1 times\n",
      "These word pairs: ('likes', 'order') appeared 1 times\n",
      "These word pairs: ('order', 'viewed') appeared 1 times\n",
      "These word pairs: ('viewed', 'users') appeared 1 times\n",
      "These word pairs: ('users', 'based') appeared 1 times\n",
      "These word pairs: ('based', 'location') appeared 1 times\n",
      "These word pairs: ('location', 'created') appeared 1 times\n",
      "These word pairs: ('created', 'graphql') appeared 1 times\n",
      "These word pairs: ('graphql', 'api') appeared 1 times\n",
      "These word pairs: ('api', 'frontend') appeared 1 times\n",
      "These word pairs: ('frontend', 'team') appeared 1 times\n",
      "These word pairs: ('team', 'successfully') appeared 1 times\n",
      "These word pairs: ('implemented', 'backend') appeared 1 times\n",
      "These word pairs: ('backend', 'geolocation') appeared 1 times\n",
      "These word pairs: ('geolocation', 'features') appeared 1 times\n",
      "These word pairs: ('features', 'tech') appeared 1 times\n",
      "These word pairs: ('heroku', 'graphql') appeared 1 times\n",
      "These word pairs: ('graphql', 'rspec') appeared 1 times\n",
      "These word pairs: ('capybara', 'sweater') appeared 1 times\n",
      "These word pairs: ('sweater', 'weather') appeared 1 times\n",
      "These word pairs: ('weather', 'api') appeared 1 times\n",
      "These word pairs: ('api', 'github') appeared 1 times\n",
      "These word pairs: ('creation', 'rest') appeared 1 times\n",
      "These word pairs: ('api', 'aggregate') appeared 1 times\n",
      "These word pairs: ('aggregate', 'data') appeared 1 times\n",
      "These word pairs: ('data', 'well') appeared 1 times\n",
      "These word pairs: ('well', 'provide') appeared 1 times\n",
      "These word pairs: ('provide', 'crud') appeared 1 times\n",
      "These word pairs: ('functionality', 'solo') appeared 1 times\n",
      "These word pairs: ('solo', 'greenfield') appeared 1 times\n",
      "These word pairs: ('greenfield', 'project') appeared 1 times\n",
      "These word pairs: ('project', 'utilize') appeared 1 times\n",
      "These word pairs: ('utilize', 'openweather') appeared 1 times\n",
      "These word pairs: ('openweather', 'mapquest') appeared 1 times\n",
      "These word pairs: ('mapquest', 'pexel') appeared 1 times\n",
      "These word pairs: ('pexel', 'api') appeared 1 times\n",
      "These word pairs: ('api', 'tech') appeared 1 times\n",
      "These word pairs: ('heroku', 'rspec') appeared 1 times\n",
      "These word pairs: ('capybara', 'monster') appeared 1 times\n",
      "These word pairs: ('monster', 'shop') appeared 1 times\n",
      "These word pairs: ('shop', 'github') appeared 1 times\n",
      "These word pairs: ('creation', 'database') appeared 1 times\n",
      "These word pairs: ('database', 'backed') appeared 1 times\n",
      "These word pairs: ('backed', 'e') appeared 1 times\n",
      "These word pairs: ('e', 'commerce') appeared 1 times\n",
      "These word pairs: ('commerce', 'application') appeared 1 times\n",
      "These word pairs: ('application', 'full') appeared 1 times\n",
      "These word pairs: ('full', 'crud') appeared 1 times\n",
      "These word pairs: ('functionality', 'successfully') appeared 1 times\n",
      "These word pairs: ('implemented', 'stretch') appeared 1 times\n",
      "These word pairs: ('stretch', 'goal') appeared 1 times\n",
      "These word pairs: ('goal', 'feature') appeared 1 times\n",
      "These word pairs: ('feature', 'automatically') appeared 1 times\n",
      "These word pairs: ('automatically', 'apply') appeared 1 times\n",
      "These word pairs: ('apply', 'discounts') appeared 1 times\n",
      "These word pairs: ('discounts', 'items') appeared 1 times\n",
      "These word pairs: ('items', 'checkout') appeared 1 times\n",
      "These word pairs: ('checkout', 'tech') appeared 1 times\n",
      "These word pairs: ('rails', 'rspec') appeared 1 times\n",
      "These word pairs: ('capybara', 'postgresql') appeared 1 times\n",
      "These word pairs: ('heroku', 'education') appeared 1 times\n",
      "These word pairs: ('education', 'backend') appeared 1 times\n",
      "These word pairs: ('engineering', 'turing') appeared 1 times\n",
      "These word pairs: ('design', 'b') appeared 1 times\n",
      "These word pairs: ('b', 'sc') appeared 1 times\n",
      "These word pairs: ('sc', 'biological') appeared 1 times\n",
      "These word pairs: ('biological', 'health') appeared 1 times\n",
      "These word pairs: ('health', 'science') appeared 1 times\n",
      "These word pairs: ('science', 'university') appeared 1 times\n",
      "These word pairs: ('university', 'south') appeared 1 times\n",
      "These word pairs: ('south', 'florida') appeared 1 times\n"
     ]
    }
   ],
   "source": [
    "def get_ordered_word_pair_frequency(concatenated_resume, window_size):\n",
    "    pair_freq = {}  # For storing the frequency of ordered word pairs\n",
    "    word_list = concatenated_resume.split()  # Splitting the concatenated text into individual words\n",
    "    \n",
    "    # Comparing adjacent words to find ordered word pairs within the window_size\n",
    "    for i in range(len(word_list) - 1):\n",
    "        word1, word2 = word_list[i], word_list[i + 1]\n",
    "        \n",
    "        # Checking if word1 and word2 are not the same before adding to pair_freq\n",
    "        if word1 != word2:\n",
    "            order_word_pair = (word1, word2)\n",
    "            if order_word_pair not in pair_freq:\n",
    "                pair_freq[order_word_pair] = 1  # If the pair is not in the dictionary, it adds it to the dictionary with a frequency of 1, indicating that we've seen it once\n",
    "            else:\n",
    "                pair_freq[order_word_pair] += 1  # It increments the frequency of the pair in the dictionary by 1, indicating that we've seen it again\n",
    "    return pair_freq\n",
    "\n",
    "window_size = 1\n",
    "\n",
    "pair_freq = get_ordered_word_pair_frequency(concatenated_resume, window_size)\n",
    "\n",
    "print(\"\\033[4mAll the Word Pairs:\\033[0m\")\n",
    "\n",
    "# Sorting all word pairs by frequency in descending order\n",
    "for pair, freq in sorted(pair_freq.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(\"These word pairs:\", pair, \"appeared\", freq, \"times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcad426",
   "metadata": {},
   "source": [
    "##### Word Frequency Calculation for Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6eb90ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique words: 202\n",
      "total number of word occurrences: 321\n",
      "\n",
      "\u001b[4mAll the words and their frequency:\u001b[0m\n",
      "surgeries appeared 7 times\n",
      "ruby appeared 6 times\n",
      "rails appeared 6 times\n",
      "neuromonitoring appeared 6 times\n",
      "software appeared 5 times\n",
      "postgresql appeared 5 times\n",
      "api appeared 5 times\n",
      "surgical appeared 5 times\n",
      "brain appeared 5 times\n",
      "github appeared 4 times\n",
      "rspec appeared 4 times\n",
      "capybara appeared 4 times\n",
      "heroku appeared 4 times\n",
      "design appeared 4 times\n",
      "backend appeared 4 times\n",
      "team appeared 4 times\n",
      "procedures appeared 4 times\n",
      "graphql appeared 3 times\n",
      "development appeared 3 times\n",
      "neurophysiologist appeared 3 times\n",
      "advanced appeared 3 times\n",
      "tumor appeared 3 times\n",
      "removal appeared 3 times\n",
      "various appeared 3 times\n",
      "patient appeared 3 times\n",
      "implemented appeared 3 times\n",
      "production appeared 3 times\n",
      "tech appeared 3 times\n",
      "johndoe appeared 2 times\n",
      "com appeared 2 times\n",
      "technical appeared 2 times\n",
      "object appeared 2 times\n",
      "oriented appeared 2 times\n",
      "test appeared 2 times\n",
      "driven appeared 2 times\n",
      "engineering appeared 2 times\n",
      "student appeared 2 times\n",
      "turing appeared 2 times\n",
      "school appeared 2 times\n",
      "projects appeared 2 times\n",
      "database appeared 2 times\n",
      "well appeared 2 times\n",
      "rest appeared 2 times\n",
      "cnim appeared 2 times\n",
      "clinic appeared 2 times\n",
      "neurophysiologists appeared 2 times\n",
      "hospitals appeared 2 times\n",
      "nationwide appeared 2 times\n",
      "lead appeared 2 times\n",
      "complex appeared 2 times\n",
      "awake appeared 2 times\n",
      "neurosurgery appeared 2 times\n",
      "provide appeared 2 times\n",
      "full appeared 2 times\n",
      "project appeared 2 times\n",
      "users appeared 2 times\n",
      "successfully appeared 2 times\n",
      "creation appeared 2 times\n",
      "crud appeared 2 times\n",
      "functionality appeared 2 times\n",
      "john appeared 1 times\n",
      "doe appeared 1 times\n",
      "engineer appeared 1 times\n",
      "www appeared 1 times\n",
      "gmail appeared 1 times\n",
      "linkedin appeared 1 times\n",
      "skills appeared 1 times\n",
      "technologies appeared 1 times\n",
      "activerecord appeared 1 times\n",
      "html appeared 1 times\n",
      "travisci appeared 1 times\n",
      "practices appeared 1 times\n",
      "programming appeared 1 times\n",
      "agile appeared 1 times\n",
      "restful appeared 1 times\n",
      "git appeared 1 times\n",
      "version appeared 1 times\n",
      "control appeared 1 times\n",
      "continuous appeared 1 times\n",
      "integration appeared 1 times\n",
      "mvc appeared 1 times\n",
      "architecture appeared 1 times\n",
      "json appeared 1 times\n",
      "construction appeared 1 times\n",
      "consumption appeared 1 times\n",
      "experience appeared 1 times\n",
      "investment appeared 1 times\n",
      "hours appeared 1 times\n",
      "creating appeared 1 times\n",
      "range appeared 1 times\n",
      "basic appeared 1 times\n",
      "applications appeared 1 times\n",
      "built appeared 1 times\n",
      "using appeared 1 times\n",
      "following appeared 1 times\n",
      "principles appeared 1 times\n",
      "success appeared 1 times\n",
      "mentor appeared 1 times\n",
      "help appeared 1 times\n",
      "current appeared 1 times\n",
      "students appeared 1 times\n",
      "understand appeared 1 times\n",
      "concepts appeared 1 times\n",
      "surrounding appeared 1 times\n",
      "oop appeared 1 times\n",
      "ttd appeared 1 times\n",
      "many appeared 1 times\n",
      "topics appeared 1 times\n",
      "senior appeared 1 times\n",
      "assure appeared 1 times\n",
      "national appeared 1 times\n",
      "technologist appeared 1 times\n",
      "part appeared 1 times\n",
      "two appeared 1 times\n",
      "member appeared 1 times\n",
      "tasked appeared 1 times\n",
      "establishing appeared 1 times\n",
      "culicchia appeared 1 times\n",
      "neurological appeared 1 times\n",
      "new appeared 1 times\n",
      "orleans appeared 1 times\n",
      "personally appeared 1 times\n",
      "trained appeared 1 times\n",
      "protocols appeared 1 times\n",
      "traveled appeared 1 times\n",
      "surgery appeared 1 times\n",
      "centers appeared 1 times\n",
      "consult appeared 1 times\n",
      "establish appeared 1 times\n",
      "nuvasive appeared 1 times\n",
      "clinical appeared 1 times\n",
      "services appeared 1 times\n",
      "mayo appeared 1 times\n",
      "including appeared 1 times\n",
      "aneurysm appeared 1 times\n",
      "multilevel appeared 1 times\n",
      "spine appeared 1 times\n",
      "asleep appeared 1 times\n",
      "worked appeared 1 times\n",
      "chief appeared 1 times\n",
      "dr appeared 1 times\n",
      "quinones appeared 1 times\n",
      "cortical appeared 1 times\n",
      "mapping appeared 1 times\n",
      "eeg appeared 1 times\n",
      "training appeared 1 times\n",
      "regimen appeared 1 times\n",
      "associate appeared 1 times\n",
      "level appeared 1 times\n",
      "transition appeared 1 times\n",
      "vascular appeared 1 times\n",
      "saturn appeared 1 times\n",
      "earth appeared 1 times\n",
      "group appeared 1 times\n",
      "stack appeared 1 times\n",
      "allowing appeared 1 times\n",
      "create appeared 1 times\n",
      "posts appeared 1 times\n",
      "gain appeared 1 times\n",
      "‘ appeared 1 times\n",
      "likes appeared 1 times\n",
      "order appeared 1 times\n",
      "viewed appeared 1 times\n",
      "based appeared 1 times\n",
      "location appeared 1 times\n",
      "created appeared 1 times\n",
      "frontend appeared 1 times\n",
      "geolocation appeared 1 times\n",
      "features appeared 1 times\n",
      "sweater appeared 1 times\n",
      "weather appeared 1 times\n",
      "aggregate appeared 1 times\n",
      "data appeared 1 times\n",
      "solo appeared 1 times\n",
      "greenfield appeared 1 times\n",
      "utilize appeared 1 times\n",
      "openweather appeared 1 times\n",
      "mapquest appeared 1 times\n",
      "pexel appeared 1 times\n",
      "monster appeared 1 times\n",
      "shop appeared 1 times\n",
      "backed appeared 1 times\n",
      "e appeared 1 times\n",
      "commerce appeared 1 times\n",
      "application appeared 1 times\n",
      "stretch appeared 1 times\n",
      "goal appeared 1 times\n",
      "feature appeared 1 times\n",
      "automatically appeared 1 times\n",
      "apply appeared 1 times\n",
      "discounts appeared 1 times\n",
      "items appeared 1 times\n",
      "checkout appeared 1 times\n",
      "education appeared 1 times\n",
      "b appeared 1 times\n",
      "sc appeared 1 times\n",
      "biological appeared 1 times\n",
      "health appeared 1 times\n",
      "science appeared 1 times\n",
      "university appeared 1 times\n",
      "south appeared 1 times\n",
      "florida appeared 1 times\n"
     ]
    }
   ],
   "source": [
    "# Counting the frequency of individual words, storing results in word_freq\n",
    "def get_single_word_frequency(processed_resume):\n",
    "    word_freq = {}  # initializing an empty dictionary called word_freq to store word frequencies\n",
    "    for review_text in processed_resume:\n",
    "        for word in review_text.split():\n",
    "            if word not in word_freq:\n",
    "                word_freq[word] = 1\n",
    "            else:\n",
    "                word_freq[word] += 1\n",
    "    return word_freq\n",
    "\n",
    "word_freq = get_single_word_frequency(processed_resume)  # Calling the function to get the word frequencies\n",
    "\n",
    "total_num_words = sum(word_freq.values())\n",
    "print('number of unique words:', len(word_freq))\n",
    "print('total number of word occurrences:', total_num_words)\n",
    "print(\"\")\n",
    "\n",
    "# Calculating and displaying the top 10 most frequently occurring words\n",
    "print(\"\\033[4mAll the words and their frequency:\\033[0m\")\n",
    "\n",
    "for word, freq in sorted(word_freq.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(word, \"appeared\", freq, \"times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142a81ff",
   "metadata": {},
   "source": [
    "##### Resume score grading (addition) Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61b0647e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume points earned (part 1): 0 points out of 14\n"
     ]
    }
   ],
   "source": [
    "# part 1 (14 points max)\n",
    "# Purpose: grading by word pairs\n",
    "\n",
    "# Logic for word pairs and their associated points\n",
    "word_pair_points = {\n",
    "    ('express', 'js'): 2,\n",
    "    ('node', 'js'): 2,\n",
    "    ('vue', 'js'): 2,\n",
    "    ('c', '#'): 2,\n",
    "    ('data', 'science'): 1,\n",
    "    ('front', 'end'): 1,\n",
    "    ('back', 'end'): 1,\n",
    "    ('web', 'scraping'): 1,\n",
    "    ('data', 'mining'): 1,\n",
    "    ('google', 'cloud'): 1,\n",
    "}\n",
    "\n",
    "# Initializing total points\n",
    "resume_points_1 = 0\n",
    "\n",
    "# Iterating through the word pairs and their frequencies\n",
    "for pair, freq in pair_freq.items():\n",
    "    # Checking if the pair is in the word_pair_points dictionary\n",
    "    if pair in word_pair_points:\n",
    "        # Adding the associated points to the total\n",
    "        resume_points_1 += word_pair_points[pair]\n",
    "\n",
    "# Printing the total points awarded\n",
    "print(\"Resume points earned (part 1):\", resume_points_1, \"points out of 14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07483a3",
   "metadata": {},
   "source": [
    "##### Resume score grading (addition) Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b930e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume points earned (part 2): 7 points out of 12\n"
     ]
    }
   ],
   "source": [
    "# part 2 (12 points max)\n",
    "# Purpose: grading by certains keywords\n",
    "\n",
    "# Initializing a dictionary to store the points for specific words\n",
    "word_points = {\n",
    "    'portfolio': 1,\n",
    "    'tensorflow': 1,\n",
    "    'github': 1,\n",
    "    'css': 1,\n",
    "    'linkedin': 1,\n",
    "    'html': 1,\n",
    "    'mongodb': 1,\n",
    "    'agile': 1,\n",
    "    'aws': 1,\n",
    "    'flask': 1,\n",
    "    'django': 1,\n",
    "    'atom': 1\n",
    "}\n",
    "\n",
    "# Initializing the total points\n",
    "resume_points_2 = 0\n",
    "\n",
    "# Iterating through the words in the processed resume\n",
    "for review_text in processed_resume:\n",
    "    for word in review_text.split():\n",
    "        # Checking if the word is in the word_points dictionary\n",
    "        if word.lower() in word_points:\n",
    "            # Adding the corresponding points to resume_points_2\n",
    "            resume_points_2 += word_points[word.lower()]\n",
    "\n",
    "# Printing the total points\n",
    "print(\"Resume points earned (part 2):\", resume_points_2, \"points out of 12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e4fd96",
   "metadata": {},
   "source": [
    "##### Resume score grading (addition) Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c246f3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume points earned (part 3a): 0 points out of 2 --> phd check \n",
      "Resume points earned (part 3b): 0 points out of 2 --> Master's degree check\n",
      "Resume points earned (part 3c): 0 points out of 4 points max --> top US Universities check i.e mostly Ivys\n",
      "Resume points earned (part 3d): 0 points out of 2 points max --> other highly rated US Universities check\n",
      "Resume points earned (part 3e): 0 points out of 2 --> Bachelors's degree check\n",
      "Resume points earned (part 3f): 0.25 points out of 2 points max --> Degree major check\n"
     ]
    }
   ],
   "source": [
    "# part 3 (14 points max)\n",
    "# Purpose: grading by education and school attended or worked in using certain keywords and wordpairs\n",
    "\n",
    "# Part 3a\n",
    "# having a doctoral degree --> 2 points\n",
    "# keyword: phd or doctoral or docorate\n",
    "\n",
    "# Initializing a dictionary to store the points for specific words\n",
    "word_points_3a = {\n",
    "    'phd': 2,\n",
    "    'doctorate': 2,\n",
    "    'doctoral': 2\n",
    "}\n",
    "\n",
    "# Initializing the total points\n",
    "resume_points_3a = 0\n",
    "\n",
    "# Iterating through the words in the processed resume\n",
    "for review_text in processed_resume:\n",
    "    for word in review_text.split():\n",
    "        # Checking if the word is in the word_points dictionary\n",
    "        if word.lower() in word_points_3a:\n",
    "            # Adding the corresponding points to resume_points_3a\n",
    "            resume_points_3a += word_points_3a[word.lower()]\n",
    "\n",
    "# Printing the total points\n",
    "print(\"Resume points earned (part 3a):\", resume_points_3a, \"points out of 2\", \"--> phd check \")\n",
    "\n",
    "\n",
    "\n",
    "# Part 3b\n",
    "# having a masters degree in the appropriate field --> 2 points\n",
    "# keyword: master\n",
    "\n",
    "# Initializing a dictionary to store the points for specific words\n",
    "word_points_3b = {\n",
    "    'master': 2\n",
    "}\n",
    "\n",
    "# Initializing the total points\n",
    "resume_points_3b = 0\n",
    "\n",
    "# Iterating through the words in the processed resume\n",
    "for review_text in processed_resume:\n",
    "    for word in review_text.split():\n",
    "        # Checking if the word is in the word_points dictionary\n",
    "        if word.lower() in word_points_3b:\n",
    "            # Adding the corresponding points to resume_points_2\n",
    "            resume_points_3b += word_points_3b[word.lower()]\n",
    "\n",
    "# Printing the total points\n",
    "print(\"Resume points earned (part 3b):\", resume_points_3b, \"points out of 2\", \"--> Master's degree check\")\n",
    "\n",
    "    \n",
    "    \n",
    "# Part 3c\n",
    "# 1 working at/ attended an <10% school --> 4 points max\n",
    "# use word pairs\n",
    "\n",
    "# Logic for word pairs and their associated points\n",
    "word_pair_points_3c = {\n",
    "    ('harvard', 'university'): 4/15,\n",
    "    ('stanford', 'university'): 4/15,\n",
    "    ('columbia', 'university'): 4/15,\n",
    "    ('california', 'institute'): 4/15,\n",
    "    ('massachusetts', 'institute'): 4/15,\n",
    "    ('university', 'chicago'):4/15,\n",
    "    ('yale', 'university'): 4/15,\n",
    "    ('princeton', 'university'): 4/15,\n",
    "    ('brown', 'university'): 4/15,\n",
    "    ('northwestern', 'university'): 4/15,\n",
    "    ('dartmouth', 'college'): 4/15,\n",
    "    ('cornell', 'university'): 4/15,\n",
    "    ('university', 'pennsylvania'): 4/15,\n",
    "    ('duke', 'university'): 4/15,\n",
    "    ('john', 'hopkins'): 4/15\n",
    "}\n",
    "\n",
    "# the more universities, the higher the points\n",
    "# 4/15 * 15 = 4 points max\n",
    "\n",
    "# Initializing total points\n",
    "resume_points_3c = 0\n",
    "\n",
    "# Iterating through the word pairs and their frequencies\n",
    "for pair, freq in pair_freq.items():\n",
    "    # Checking if the pair is in the word_pair_points_major dictionary\n",
    "    if pair in word_pair_points_3c:\n",
    "        # Adding the associated points to the total\n",
    "        resume_points_3c += word_pair_points_3c[pair]\n",
    "\n",
    "# Printing the total points awarded for this section\n",
    "print(\"Resume points earned (part 3c):\", resume_points_3c, \"points out of 4 points max\", \"--> top US Universities check i.e mostly Ivys\")\n",
    "\n",
    "\n",
    "\n",
    "# Part 3d\n",
    "# working at/ attended an <20% school --> 2 points max\n",
    "# use word pairs and keywords\n",
    "\n",
    "# Logic for word pairs and their associated points\n",
    "word_pair_points_3d = {\n",
    "    ('southern', 'california'): 0.2,\n",
    "    ('vanderbilt', 'university'): 0.2,\n",
    "    ('washington', 'university'): 0.2,\n",
    "    ('rice', 'university'): 0.2,\n",
    "    ('georgetown', 'university'): 0.2,\n",
    "    ('emory', 'university'): 0.2,\n",
    "    ('carnegie', 'mellon'): 0.2,\n",
    "    ('notre', 'dame'): 0.2,\n",
    "    ('boston', 'university'): 0.2,\n",
    "    ('tufts', 'university'): 0.2\n",
    "}\n",
    "\n",
    "# the more universities, the higher the points\n",
    "# 0.2 * 10 = 2 points max\n",
    "\n",
    "# Initializing total points\n",
    "resume_points_3d = 0\n",
    "\n",
    "# Iterating through the word pairs and their frequencies\n",
    "for pair, freq in pair_freq.items():\n",
    "    # Checking if the pair is in the word_pair_points_major dictionary\n",
    "    if pair in word_pair_points_3d:\n",
    "        # Adding the associated points to the total\n",
    "        resume_points_3d += word_pair_points_3d[pair]\n",
    "\n",
    "# Printing the total points awarded for this section\n",
    "print(\"Resume points earned (part 3d):\", resume_points_3d, \"points out of 2 points max\", \"--> other highly rated US Universities check\")  \n",
    "\n",
    "\n",
    "    \n",
    "# Part 3e\n",
    "# having a bachelor's degree --> 2 points\n",
    "# keyword: bachelor\n",
    "# Initializing a dictionary to store the points for specific words\n",
    "word_points_3e = {\n",
    "    'bachelor': 2\n",
    "}\n",
    "\n",
    "# Initializing the total points\n",
    "resume_points_3e = 0\n",
    "\n",
    "# Iterating through the words in the processed resume\n",
    "for review_text in processed_resume:\n",
    "    for word in review_text.split():\n",
    "        # Checking if the word is in the word_points dictionary\n",
    "        if word.lower() in word_points_3e:\n",
    "            # Adding the corresponding points to resume_points_2\n",
    "            resume_points_3e += word_points_3e[word.lower()]\n",
    "\n",
    "# Printing the total points\n",
    "print(\"Resume points earned (part 3e):\", resume_points_3e, \"points out of 2\", \"--> Bachelors's degree check\")\n",
    "\n",
    "    \n",
    "    \n",
    "# Part 3f\n",
    "# major type --> 2 points\n",
    "# looks for word pairs for: Computer Science, Information Science, Software Engineering, Computer Engineering, \n",
    "# Electrical Engineering, Information Technology, Information Systems,Systems Engineering\n",
    "    \n",
    "# Logic for word pairs and their associated points\n",
    "word_pair_points_3f = {\n",
    "    ('computer', 'science'): 0.25,\n",
    "    ('information', 'science'): 0.25,\n",
    "    ('software', 'engineering'): 0.25,\n",
    "    ('computer', 'engineering'): 0.25,\n",
    "    ('electrical', 'engineering'): 0.25,\n",
    "    ('information', 'technology'): 0.25,\n",
    "    ('information', 'systems'): 0.25,\n",
    "    ('systems', 'engineering'): 0.25\n",
    "}\n",
    "\n",
    "# the more majors, the higher the points\n",
    "# 0.25 * 8 = 2 points\n",
    "\n",
    "# Initializing total points\n",
    "resume_points_3f = 0\n",
    "\n",
    "# Iterating through the word pairs and their frequencies\n",
    "for pair, freq in pair_freq.items():\n",
    "    # Checking if the pair is in the word_pair_points_major dictionary\n",
    "    if pair in word_pair_points_3f:\n",
    "        # Adding the associated points to the total\n",
    "        resume_points_3f += word_pair_points_3f[pair]\n",
    "\n",
    "# Printing the total points awarded for this section\n",
    "print(\"Resume points earned (part 3f):\", resume_points_3f, \"points out of 2 points max\", \"--> Degree major check\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c79dc12",
   "metadata": {},
   "source": [
    "##### Resume score grading (addition) Total Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e224abd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume points earned: 7.25 points out of 40\n"
     ]
    }
   ],
   "source": [
    "# Taking the total points earned for the resume\n",
    "resume_points_earned = (resume_points_1 + resume_points_2 + resume_points_3a + resume_points_3b + resume_points_3c + \n",
    "                       resume_points_3d + resume_points_3e + resume_points_3f)\n",
    "# Break down:\n",
    "# resume_points_1: 14 max\n",
    "# resume_points_2: 12 max\n",
    "# resume_points_3: 14 max\n",
    "# Total: 40 max points\n",
    "\n",
    "print(\"Resume points earned:\", resume_points_earned, \"points out of 40\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60a8bb4",
   "metadata": {},
   "source": [
    "##### Resume score grading (subtraction) part 4 and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6bd806c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume points deducted (part 4): 0 points out of 5 points max deduction\n"
     ]
    }
   ],
   "source": [
    "# For Word Pairs Point Substraction\n",
    "\n",
    "# Logic for word pairs and their associated points\n",
    "word_pair_points_4 = {\n",
    "    ('detail', 'oriented'): 0.5,\n",
    "    ('team', 'player'): 0.5,\n",
    "    ('go', 'getter'): 0.5,\n",
    "    ('multiple', 'tasks'): 0.5,\n",
    "    ('highly', 'motivated'): 0.5,\n",
    "    ('problem', 'solver'): 0.5,\n",
    "    ('worked', 'on'): 0.5,\n",
    "    ('took', 'orders'): 0.5,\n",
    "    ('time', 'management'): 0.5,\n",
    "    ('innovative', 'thinker'): 0.5\n",
    "}\n",
    "\n",
    "# the more words, the higher the points deduction\n",
    "# 0.5 * 10 = 5 points max deduction\n",
    "\n",
    "# Initializing total points\n",
    "resume_points_4 = 0\n",
    "\n",
    "# Iterating through the word pairs and their frequencies\n",
    "for pair, freq in pair_freq.items():\n",
    "    # Checking if the pair is in the word_pair_points_major dictionary\n",
    "    if pair in word_pair_points_4:\n",
    "        # Adding the associated points to the total\n",
    "        resume_points_4 += word_pair_points_4[pair]\n",
    "\n",
    "# Printing the total points awarded for this section\n",
    "print(\"Resume points deducted (part 4):\", resume_points_4, \"points out of 5 points max deduction\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7ce2c199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume points deducted (part 5): 0 points out of 8.5 points max deduction\n"
     ]
    }
   ],
   "source": [
    "# For Key words Point Substraction\n",
    "\n",
    "# Initializing a dictionary to store the points for specific words\n",
    "word_points_5 = {\n",
    "    'passionate': 0.5,\n",
    "    'challenging': 0.5,\n",
    "    'references': 0.5,\n",
    "    'innovative': 0.5,\n",
    "    'creative': 0.5,\n",
    "    'helped': 0.5,\n",
    "    'sold': 0.5,\n",
    "    'hard': 0.5,\n",
    "    'great': 0.5,\n",
    "    'difficult': 0.5,\n",
    "    'bad': 0.5,\n",
    "    'good': 0.5,\n",
    "    'amazing': 0.5,\n",
    "    'strong': 0.5,\n",
    "    'knack': 0.5,\n",
    "    'excellent': 0.5,\n",
    "    'communicator': 0.5\n",
    "}\n",
    "\n",
    "# the more words, the higher the points deduction\n",
    "# 0.5 * 17 = 8.5 points max deduction\n",
    "\n",
    "# Initializing the total points\n",
    "resume_points_5 = 0\n",
    "\n",
    "# Iterating through the words in the processed resume\n",
    "for review_text in processed_resume:\n",
    "    for word in review_text.split():\n",
    "        # Checking if the word is in the word_points dictionary\n",
    "        if word.lower() in word_points_5:\n",
    "            # Adding the corresponding points to resume_points_2\n",
    "            resume_points_5 += word_points_5[word.lower()]\n",
    "\n",
    "# Printing the total points\n",
    "print(\"Resume points deducted (part 5):\", resume_points_5, \"points out of 8.5 points max deduction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ae0adf",
   "metadata": {},
   "source": [
    "##### Total Resume Calculation (Points - deduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "98742bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume total (out of 40): 7.25\n"
     ]
    }
   ],
   "source": [
    "resume_percent = \"{:.2f}\".format(resume_points_earned - (resume_points_4 + resume_points_5))\n",
    "print(\"Resume total (out of 40):\", resume_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8b9d11",
   "metadata": {},
   "source": [
    "### Cover Letter Analysis and Grading Section (40%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17d18df",
   "metadata": {},
   "source": [
    "##### Removing StopWords, Numerical Digits, Punctuations, Symbols, Extra Spaces, Making Text lowercase and Normalizing and Tokenizing the Text from Cover Letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f7860401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Adding auxiliary verbs to the stopwords list\n",
    "auxiliary_verbs = ['am', 'is', 'are', 'was', 'were', 'be', 'been', 'being',\n",
    "                   'have', 'has', 'had', 'do', 'does', 'did', 'can', 'could',\n",
    "                   'shall', 'should', 'will', 'would', 'may', 'might', 'must']\n",
    "\n",
    "stop_words.update(auxiliary_verbs)\n",
    "\n",
    "# Initializing a list to store the processed cover letter\n",
    "processed_cover_letter = []\n",
    "\n",
    "# Opening and reading the original file\n",
    "with open(cover_letter_filepath, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        cover_letter_text = line.strip()\n",
    "        \n",
    "        # Text cleaning and normalization\n",
    "        for punctuations_and_more in ['●','–', ',', '.', '\"', '!', '?', ':', ';', '-', '(', ')', '[', ']', \"'\", '*', '$', '/', '+','’', \n",
    "                             '_','|','@']:\n",
    "            cover_letter_text = cover_letter_text.replace(punctuations_and_more, ' ')  # Replacing punctuations with spaces\n",
    "            cover_letter_text = re.sub('\\s+', ' ', cover_letter_text)  # Removing extra spaces\n",
    "            cover_letter_text = cover_letter_text.lower().strip()  # Making text lowercase\n",
    "\n",
    "        # Removing numerical digits\n",
    "        cover_letter_text = re.sub(r'\\d', '', cover_letter_text)\n",
    "        \n",
    "        # Tokenizing the cleaned cover letter text\n",
    "        words = nltk.word_tokenize(cover_letter_text)\n",
    "        \n",
    "        # Removing stopwords, including auxiliary verbs\n",
    "        filtered_words = [word for word in words if word not in stop_words]\n",
    "        \n",
    "        # Joining the filtered words back into a sentence\n",
    "        processed_cover_letter_x = ' '.join(filtered_words)\n",
    "        \n",
    "        processed_cover_letter.append(processed_cover_letter_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d3ae5c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dear hiring manager', 'writing express interest full stack software engineer summer intern position', 'neptune technologies advertised proactive results driven software engineer bring', 'unique blend skills experiences align core preferred qualifications', 'outlined role', 'throughout academic journey extensive hands experience actively pursued', 'bachelor degree backend software engineering turing school software design', 'demonstrating strong record academic achievement currently student success mentor', 'assisting peers grasping technical concepts surrounding ruby rails postgresql oop ttd', 'projects including development full stack application called saturn', 'earth showcase proficiency technologies ruby rails postgresql heroku', 'graphql', 'addition development skills possess robust understanding computer science', 'mathematics system design background senior surgical neurophysiologist equipped', 'unique perspective system management collaborative teamwork believe', 'valuable dynamic environment like neptune technologies implemented', 'advanced neuromonitoring procedures trained fellow professionals highlighting', 'leadership mentoring capabilities', 'furthermore technical skills align closely preferred qualifications encompassing', 'proficiency git experience ci cd restful api design development using node js', 'knowledge database technologies postgresql projects including sweater', 'weather api monster shop reflect ability develop meaningful software applications', 'implement features enhance user experience', 'particularly drawn neptune technologies due innovative approach technology', 'excited prospect contributing skills knowledge team', 'commitment continuous learning technical expertise collaborative mindset make', 'ideal candidate internship available work hours week weeks', 'august eager contribute success neptune technologies', 'thank considering application look forward opportunity discuss', 'skills experiences align goals neptune technologies', 'sincerely', 'john doe', 'johndoe gmail com', '']\n"
     ]
    }
   ],
   "source": [
    "# Displaying processed_cover_letter\n",
    "print(processed_cover_letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a5a7aa",
   "metadata": {},
   "source": [
    "##### Combining all lines in processed_cover_letter into a single line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e54109e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dear hiring manager writing express interest full stack software engineer summer intern position neptune technologies advertised proactive results driven software engineer bring unique blend skills experiences align core preferred qualifications outlined role throughout academic journey extensive hands experience actively pursued bachelor degree backend software engineering turing school software design demonstrating strong record academic achievement currently student success mentor assisting peers grasping technical concepts surrounding ruby rails postgresql oop ttd projects including development full stack application called saturn earth showcase proficiency technologies ruby rails postgresql heroku graphql addition development skills possess robust understanding computer science mathematics system design background senior surgical neurophysiologist equipped unique perspective system management collaborative teamwork believe valuable dynamic environment like neptune technologies implemented advanced neuromonitoring procedures trained fellow professionals highlighting leadership mentoring capabilities furthermore technical skills align closely preferred qualifications encompassing proficiency git experience ci cd restful api design development using node js knowledge database technologies postgresql projects including sweater weather api monster shop reflect ability develop meaningful software applications implement features enhance user experience particularly drawn neptune technologies due innovative approach technology excited prospect contributing skills knowledge team commitment continuous learning technical expertise collaborative mindset make ideal candidate internship available work hours week weeks august eager contribute success neptune technologies thank considering application look forward opportunity discuss skills experiences align goals neptune technologies sincerely john doe johndoe gmail com \n"
     ]
    }
   ],
   "source": [
    "concatenated_cover_letter = ' '.join(processed_cover_letter)\n",
    "print(concatenated_cover_letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6ae692",
   "metadata": {},
   "source": [
    "##### Word Pairs Calculation for Cover Letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0eb09730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4mAll the Word Pairs:\u001b[0m\n",
      "These word pairs: ('neptune', 'technologies') appeared 5 times\n",
      "These word pairs: ('full', 'stack') appeared 2 times\n",
      "These word pairs: ('software', 'engineer') appeared 2 times\n",
      "These word pairs: ('skills', 'experiences') appeared 2 times\n",
      "These word pairs: ('experiences', 'align') appeared 2 times\n",
      "These word pairs: ('preferred', 'qualifications') appeared 2 times\n",
      "These word pairs: ('ruby', 'rails') appeared 2 times\n",
      "These word pairs: ('rails', 'postgresql') appeared 2 times\n",
      "These word pairs: ('projects', 'including') appeared 2 times\n",
      "These word pairs: ('dear', 'hiring') appeared 1 times\n",
      "These word pairs: ('hiring', 'manager') appeared 1 times\n",
      "These word pairs: ('manager', 'writing') appeared 1 times\n",
      "These word pairs: ('writing', 'express') appeared 1 times\n",
      "These word pairs: ('express', 'interest') appeared 1 times\n",
      "These word pairs: ('interest', 'full') appeared 1 times\n",
      "These word pairs: ('stack', 'software') appeared 1 times\n",
      "These word pairs: ('engineer', 'summer') appeared 1 times\n",
      "These word pairs: ('summer', 'intern') appeared 1 times\n",
      "These word pairs: ('intern', 'position') appeared 1 times\n",
      "These word pairs: ('position', 'neptune') appeared 1 times\n",
      "These word pairs: ('technologies', 'advertised') appeared 1 times\n",
      "These word pairs: ('advertised', 'proactive') appeared 1 times\n",
      "These word pairs: ('proactive', 'results') appeared 1 times\n",
      "These word pairs: ('results', 'driven') appeared 1 times\n",
      "These word pairs: ('driven', 'software') appeared 1 times\n",
      "These word pairs: ('engineer', 'bring') appeared 1 times\n",
      "These word pairs: ('bring', 'unique') appeared 1 times\n",
      "These word pairs: ('unique', 'blend') appeared 1 times\n",
      "These word pairs: ('blend', 'skills') appeared 1 times\n",
      "These word pairs: ('align', 'core') appeared 1 times\n",
      "These word pairs: ('core', 'preferred') appeared 1 times\n",
      "These word pairs: ('qualifications', 'outlined') appeared 1 times\n",
      "These word pairs: ('outlined', 'role') appeared 1 times\n",
      "These word pairs: ('role', 'throughout') appeared 1 times\n",
      "These word pairs: ('throughout', 'academic') appeared 1 times\n",
      "These word pairs: ('academic', 'journey') appeared 1 times\n",
      "These word pairs: ('journey', 'extensive') appeared 1 times\n",
      "These word pairs: ('extensive', 'hands') appeared 1 times\n",
      "These word pairs: ('hands', 'experience') appeared 1 times\n",
      "These word pairs: ('experience', 'actively') appeared 1 times\n",
      "These word pairs: ('actively', 'pursued') appeared 1 times\n",
      "These word pairs: ('pursued', 'bachelor') appeared 1 times\n",
      "These word pairs: ('bachelor', 'degree') appeared 1 times\n",
      "These word pairs: ('degree', 'backend') appeared 1 times\n",
      "These word pairs: ('backend', 'software') appeared 1 times\n",
      "These word pairs: ('software', 'engineering') appeared 1 times\n",
      "These word pairs: ('engineering', 'turing') appeared 1 times\n",
      "These word pairs: ('turing', 'school') appeared 1 times\n",
      "These word pairs: ('school', 'software') appeared 1 times\n",
      "These word pairs: ('software', 'design') appeared 1 times\n",
      "These word pairs: ('design', 'demonstrating') appeared 1 times\n",
      "These word pairs: ('demonstrating', 'strong') appeared 1 times\n",
      "These word pairs: ('strong', 'record') appeared 1 times\n",
      "These word pairs: ('record', 'academic') appeared 1 times\n",
      "These word pairs: ('academic', 'achievement') appeared 1 times\n",
      "These word pairs: ('achievement', 'currently') appeared 1 times\n",
      "These word pairs: ('currently', 'student') appeared 1 times\n",
      "These word pairs: ('student', 'success') appeared 1 times\n",
      "These word pairs: ('success', 'mentor') appeared 1 times\n",
      "These word pairs: ('mentor', 'assisting') appeared 1 times\n",
      "These word pairs: ('assisting', 'peers') appeared 1 times\n",
      "These word pairs: ('peers', 'grasping') appeared 1 times\n",
      "These word pairs: ('grasping', 'technical') appeared 1 times\n",
      "These word pairs: ('technical', 'concepts') appeared 1 times\n",
      "These word pairs: ('concepts', 'surrounding') appeared 1 times\n",
      "These word pairs: ('surrounding', 'ruby') appeared 1 times\n",
      "These word pairs: ('postgresql', 'oop') appeared 1 times\n",
      "These word pairs: ('oop', 'ttd') appeared 1 times\n",
      "These word pairs: ('ttd', 'projects') appeared 1 times\n",
      "These word pairs: ('including', 'development') appeared 1 times\n",
      "These word pairs: ('development', 'full') appeared 1 times\n",
      "These word pairs: ('stack', 'application') appeared 1 times\n",
      "These word pairs: ('application', 'called') appeared 1 times\n",
      "These word pairs: ('called', 'saturn') appeared 1 times\n",
      "These word pairs: ('saturn', 'earth') appeared 1 times\n",
      "These word pairs: ('earth', 'showcase') appeared 1 times\n",
      "These word pairs: ('showcase', 'proficiency') appeared 1 times\n",
      "These word pairs: ('proficiency', 'technologies') appeared 1 times\n",
      "These word pairs: ('technologies', 'ruby') appeared 1 times\n",
      "These word pairs: ('postgresql', 'heroku') appeared 1 times\n",
      "These word pairs: ('heroku', 'graphql') appeared 1 times\n",
      "These word pairs: ('graphql', 'addition') appeared 1 times\n",
      "These word pairs: ('addition', 'development') appeared 1 times\n",
      "These word pairs: ('development', 'skills') appeared 1 times\n",
      "These word pairs: ('skills', 'possess') appeared 1 times\n",
      "These word pairs: ('possess', 'robust') appeared 1 times\n",
      "These word pairs: ('robust', 'understanding') appeared 1 times\n",
      "These word pairs: ('understanding', 'computer') appeared 1 times\n",
      "These word pairs: ('computer', 'science') appeared 1 times\n",
      "These word pairs: ('science', 'mathematics') appeared 1 times\n",
      "These word pairs: ('mathematics', 'system') appeared 1 times\n",
      "These word pairs: ('system', 'design') appeared 1 times\n",
      "These word pairs: ('design', 'background') appeared 1 times\n",
      "These word pairs: ('background', 'senior') appeared 1 times\n",
      "These word pairs: ('senior', 'surgical') appeared 1 times\n",
      "These word pairs: ('surgical', 'neurophysiologist') appeared 1 times\n",
      "These word pairs: ('neurophysiologist', 'equipped') appeared 1 times\n",
      "These word pairs: ('equipped', 'unique') appeared 1 times\n",
      "These word pairs: ('unique', 'perspective') appeared 1 times\n",
      "These word pairs: ('perspective', 'system') appeared 1 times\n",
      "These word pairs: ('system', 'management') appeared 1 times\n",
      "These word pairs: ('management', 'collaborative') appeared 1 times\n",
      "These word pairs: ('collaborative', 'teamwork') appeared 1 times\n",
      "These word pairs: ('teamwork', 'believe') appeared 1 times\n",
      "These word pairs: ('believe', 'valuable') appeared 1 times\n",
      "These word pairs: ('valuable', 'dynamic') appeared 1 times\n",
      "These word pairs: ('dynamic', 'environment') appeared 1 times\n",
      "These word pairs: ('environment', 'like') appeared 1 times\n",
      "These word pairs: ('like', 'neptune') appeared 1 times\n",
      "These word pairs: ('technologies', 'implemented') appeared 1 times\n",
      "These word pairs: ('implemented', 'advanced') appeared 1 times\n",
      "These word pairs: ('advanced', 'neuromonitoring') appeared 1 times\n",
      "These word pairs: ('neuromonitoring', 'procedures') appeared 1 times\n",
      "These word pairs: ('procedures', 'trained') appeared 1 times\n",
      "These word pairs: ('trained', 'fellow') appeared 1 times\n",
      "These word pairs: ('fellow', 'professionals') appeared 1 times\n",
      "These word pairs: ('professionals', 'highlighting') appeared 1 times\n",
      "These word pairs: ('highlighting', 'leadership') appeared 1 times\n",
      "These word pairs: ('leadership', 'mentoring') appeared 1 times\n",
      "These word pairs: ('mentoring', 'capabilities') appeared 1 times\n",
      "These word pairs: ('capabilities', 'furthermore') appeared 1 times\n",
      "These word pairs: ('furthermore', 'technical') appeared 1 times\n",
      "These word pairs: ('technical', 'skills') appeared 1 times\n",
      "These word pairs: ('skills', 'align') appeared 1 times\n",
      "These word pairs: ('align', 'closely') appeared 1 times\n",
      "These word pairs: ('closely', 'preferred') appeared 1 times\n",
      "These word pairs: ('qualifications', 'encompassing') appeared 1 times\n",
      "These word pairs: ('encompassing', 'proficiency') appeared 1 times\n",
      "These word pairs: ('proficiency', 'git') appeared 1 times\n",
      "These word pairs: ('git', 'experience') appeared 1 times\n",
      "These word pairs: ('experience', 'ci') appeared 1 times\n",
      "These word pairs: ('ci', 'cd') appeared 1 times\n",
      "These word pairs: ('cd', 'restful') appeared 1 times\n",
      "These word pairs: ('restful', 'api') appeared 1 times\n",
      "These word pairs: ('api', 'design') appeared 1 times\n",
      "These word pairs: ('design', 'development') appeared 1 times\n",
      "These word pairs: ('development', 'using') appeared 1 times\n",
      "These word pairs: ('using', 'node') appeared 1 times\n",
      "These word pairs: ('node', 'js') appeared 1 times\n",
      "These word pairs: ('js', 'knowledge') appeared 1 times\n",
      "These word pairs: ('knowledge', 'database') appeared 1 times\n",
      "These word pairs: ('database', 'technologies') appeared 1 times\n",
      "These word pairs: ('technologies', 'postgresql') appeared 1 times\n",
      "These word pairs: ('postgresql', 'projects') appeared 1 times\n",
      "These word pairs: ('including', 'sweater') appeared 1 times\n",
      "These word pairs: ('sweater', 'weather') appeared 1 times\n",
      "These word pairs: ('weather', 'api') appeared 1 times\n",
      "These word pairs: ('api', 'monster') appeared 1 times\n",
      "These word pairs: ('monster', 'shop') appeared 1 times\n",
      "These word pairs: ('shop', 'reflect') appeared 1 times\n",
      "These word pairs: ('reflect', 'ability') appeared 1 times\n",
      "These word pairs: ('ability', 'develop') appeared 1 times\n",
      "These word pairs: ('develop', 'meaningful') appeared 1 times\n",
      "These word pairs: ('meaningful', 'software') appeared 1 times\n",
      "These word pairs: ('software', 'applications') appeared 1 times\n",
      "These word pairs: ('applications', 'implement') appeared 1 times\n",
      "These word pairs: ('implement', 'features') appeared 1 times\n",
      "These word pairs: ('features', 'enhance') appeared 1 times\n",
      "These word pairs: ('enhance', 'user') appeared 1 times\n",
      "These word pairs: ('user', 'experience') appeared 1 times\n",
      "These word pairs: ('experience', 'particularly') appeared 1 times\n",
      "These word pairs: ('particularly', 'drawn') appeared 1 times\n",
      "These word pairs: ('drawn', 'neptune') appeared 1 times\n",
      "These word pairs: ('technologies', 'due') appeared 1 times\n",
      "These word pairs: ('due', 'innovative') appeared 1 times\n",
      "These word pairs: ('innovative', 'approach') appeared 1 times\n",
      "These word pairs: ('approach', 'technology') appeared 1 times\n",
      "These word pairs: ('technology', 'excited') appeared 1 times\n",
      "These word pairs: ('excited', 'prospect') appeared 1 times\n",
      "These word pairs: ('prospect', 'contributing') appeared 1 times\n",
      "These word pairs: ('contributing', 'skills') appeared 1 times\n",
      "These word pairs: ('skills', 'knowledge') appeared 1 times\n",
      "These word pairs: ('knowledge', 'team') appeared 1 times\n",
      "These word pairs: ('team', 'commitment') appeared 1 times\n",
      "These word pairs: ('commitment', 'continuous') appeared 1 times\n",
      "These word pairs: ('continuous', 'learning') appeared 1 times\n",
      "These word pairs: ('learning', 'technical') appeared 1 times\n",
      "These word pairs: ('technical', 'expertise') appeared 1 times\n",
      "These word pairs: ('expertise', 'collaborative') appeared 1 times\n",
      "These word pairs: ('collaborative', 'mindset') appeared 1 times\n",
      "These word pairs: ('mindset', 'make') appeared 1 times\n",
      "These word pairs: ('make', 'ideal') appeared 1 times\n",
      "These word pairs: ('ideal', 'candidate') appeared 1 times\n",
      "These word pairs: ('candidate', 'internship') appeared 1 times\n",
      "These word pairs: ('internship', 'available') appeared 1 times\n",
      "These word pairs: ('available', 'work') appeared 1 times\n",
      "These word pairs: ('work', 'hours') appeared 1 times\n",
      "These word pairs: ('hours', 'week') appeared 1 times\n",
      "These word pairs: ('week', 'weeks') appeared 1 times\n",
      "These word pairs: ('weeks', 'august') appeared 1 times\n",
      "These word pairs: ('august', 'eager') appeared 1 times\n",
      "These word pairs: ('eager', 'contribute') appeared 1 times\n",
      "These word pairs: ('contribute', 'success') appeared 1 times\n",
      "These word pairs: ('success', 'neptune') appeared 1 times\n",
      "These word pairs: ('technologies', 'thank') appeared 1 times\n",
      "These word pairs: ('thank', 'considering') appeared 1 times\n",
      "These word pairs: ('considering', 'application') appeared 1 times\n",
      "These word pairs: ('application', 'look') appeared 1 times\n",
      "These word pairs: ('look', 'forward') appeared 1 times\n",
      "These word pairs: ('forward', 'opportunity') appeared 1 times\n",
      "These word pairs: ('opportunity', 'discuss') appeared 1 times\n",
      "These word pairs: ('discuss', 'skills') appeared 1 times\n",
      "These word pairs: ('align', 'goals') appeared 1 times\n",
      "These word pairs: ('goals', 'neptune') appeared 1 times\n",
      "These word pairs: ('technologies', 'sincerely') appeared 1 times\n",
      "These word pairs: ('sincerely', 'john') appeared 1 times\n",
      "These word pairs: ('john', 'doe') appeared 1 times\n",
      "These word pairs: ('doe', 'johndoe') appeared 1 times\n",
      "These word pairs: ('johndoe', 'gmail') appeared 1 times\n",
      "These word pairs: ('gmail', 'com') appeared 1 times\n"
     ]
    }
   ],
   "source": [
    "def get_ordered_word_pair_frequency(concatenated_cover_letter, window_size):\n",
    "    pair_freq = {}  # For storing the frequency of ordered word pairs\n",
    "    word_list = concatenated_cover_letter.split()  # Splitting the concatenated text into individual words\n",
    "\n",
    "    # Comparing adjacent words to find ordered word pairs within the window_size\n",
    "    for i in range(len(word_list) - 1):\n",
    "        word1, word2 = word_list[i], word_list[i + 1]\n",
    "\n",
    "        # Checking if word1 and word2 are not the same before adding to pair_freq\n",
    "        if word1 != word2:\n",
    "            order_word_pair = (word1, word2)\n",
    "            if order_word_pair not in pair_freq:\n",
    "                pair_freq[order_word_pair] = 1  # If the pair is not in the dictionary, it adds it to the dictionary with a frequency of 1, indicating that we've seen it once\n",
    "            else:\n",
    "                pair_freq[order_word_pair] += 1  # It increments the frequency of the pair in the dictionary by 1, indicating that we've seen it again\n",
    "    return pair_freq\n",
    "\n",
    "window_size = 1\n",
    "\n",
    "pair_freq = get_ordered_word_pair_frequency(concatenated_cover_letter, window_size)\n",
    "\n",
    "print(\"\\033[4mAll the Word Pairs:\\033[0m\")\n",
    "\n",
    "# Sorting all word pairs by frequency in descending order\n",
    "for pair, freq in sorted(pair_freq.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(\"These word pairs:\", pair, \"appeared\", freq, \"times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20148ae",
   "metadata": {},
   "source": [
    "##### Word Frequency Calculation for Cover Letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b5c74c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique words: 174\n",
      "total number of word occurrences: 223\n",
      "\n",
      "\u001b[4mAll the words and their frequency:\u001b[0m\n",
      "technologies appeared 7 times\n",
      "software appeared 5 times\n",
      "neptune appeared 5 times\n",
      "skills appeared 5 times\n",
      "align appeared 3 times\n",
      "experience appeared 3 times\n",
      "design appeared 3 times\n",
      "technical appeared 3 times\n",
      "postgresql appeared 3 times\n",
      "development appeared 3 times\n",
      "full appeared 2 times\n",
      "stack appeared 2 times\n",
      "engineer appeared 2 times\n",
      "unique appeared 2 times\n",
      "experiences appeared 2 times\n",
      "preferred appeared 2 times\n",
      "qualifications appeared 2 times\n",
      "academic appeared 2 times\n",
      "success appeared 2 times\n",
      "ruby appeared 2 times\n",
      "rails appeared 2 times\n",
      "projects appeared 2 times\n",
      "including appeared 2 times\n",
      "application appeared 2 times\n",
      "proficiency appeared 2 times\n",
      "system appeared 2 times\n",
      "collaborative appeared 2 times\n",
      "api appeared 2 times\n",
      "knowledge appeared 2 times\n",
      "dear appeared 1 times\n",
      "hiring appeared 1 times\n",
      "manager appeared 1 times\n",
      "writing appeared 1 times\n",
      "express appeared 1 times\n",
      "interest appeared 1 times\n",
      "summer appeared 1 times\n",
      "intern appeared 1 times\n",
      "position appeared 1 times\n",
      "advertised appeared 1 times\n",
      "proactive appeared 1 times\n",
      "results appeared 1 times\n",
      "driven appeared 1 times\n",
      "bring appeared 1 times\n",
      "blend appeared 1 times\n",
      "core appeared 1 times\n",
      "outlined appeared 1 times\n",
      "role appeared 1 times\n",
      "throughout appeared 1 times\n",
      "journey appeared 1 times\n",
      "extensive appeared 1 times\n",
      "hands appeared 1 times\n",
      "actively appeared 1 times\n",
      "pursued appeared 1 times\n",
      "bachelor appeared 1 times\n",
      "degree appeared 1 times\n",
      "backend appeared 1 times\n",
      "engineering appeared 1 times\n",
      "turing appeared 1 times\n",
      "school appeared 1 times\n",
      "demonstrating appeared 1 times\n",
      "strong appeared 1 times\n",
      "record appeared 1 times\n",
      "achievement appeared 1 times\n",
      "currently appeared 1 times\n",
      "student appeared 1 times\n",
      "mentor appeared 1 times\n",
      "assisting appeared 1 times\n",
      "peers appeared 1 times\n",
      "grasping appeared 1 times\n",
      "concepts appeared 1 times\n",
      "surrounding appeared 1 times\n",
      "oop appeared 1 times\n",
      "ttd appeared 1 times\n",
      "called appeared 1 times\n",
      "saturn appeared 1 times\n",
      "earth appeared 1 times\n",
      "showcase appeared 1 times\n",
      "heroku appeared 1 times\n",
      "graphql appeared 1 times\n",
      "addition appeared 1 times\n",
      "possess appeared 1 times\n",
      "robust appeared 1 times\n",
      "understanding appeared 1 times\n",
      "computer appeared 1 times\n",
      "science appeared 1 times\n",
      "mathematics appeared 1 times\n",
      "background appeared 1 times\n",
      "senior appeared 1 times\n",
      "surgical appeared 1 times\n",
      "neurophysiologist appeared 1 times\n",
      "equipped appeared 1 times\n",
      "perspective appeared 1 times\n",
      "management appeared 1 times\n",
      "teamwork appeared 1 times\n",
      "believe appeared 1 times\n",
      "valuable appeared 1 times\n",
      "dynamic appeared 1 times\n",
      "environment appeared 1 times\n",
      "like appeared 1 times\n",
      "implemented appeared 1 times\n",
      "advanced appeared 1 times\n",
      "neuromonitoring appeared 1 times\n",
      "procedures appeared 1 times\n",
      "trained appeared 1 times\n",
      "fellow appeared 1 times\n",
      "professionals appeared 1 times\n",
      "highlighting appeared 1 times\n",
      "leadership appeared 1 times\n",
      "mentoring appeared 1 times\n",
      "capabilities appeared 1 times\n",
      "furthermore appeared 1 times\n",
      "closely appeared 1 times\n",
      "encompassing appeared 1 times\n",
      "git appeared 1 times\n",
      "ci appeared 1 times\n",
      "cd appeared 1 times\n",
      "restful appeared 1 times\n",
      "using appeared 1 times\n",
      "node appeared 1 times\n",
      "js appeared 1 times\n",
      "database appeared 1 times\n",
      "sweater appeared 1 times\n",
      "weather appeared 1 times\n",
      "monster appeared 1 times\n",
      "shop appeared 1 times\n",
      "reflect appeared 1 times\n",
      "ability appeared 1 times\n",
      "develop appeared 1 times\n",
      "meaningful appeared 1 times\n",
      "applications appeared 1 times\n",
      "implement appeared 1 times\n",
      "features appeared 1 times\n",
      "enhance appeared 1 times\n",
      "user appeared 1 times\n",
      "particularly appeared 1 times\n",
      "drawn appeared 1 times\n",
      "due appeared 1 times\n",
      "innovative appeared 1 times\n",
      "approach appeared 1 times\n",
      "technology appeared 1 times\n",
      "excited appeared 1 times\n",
      "prospect appeared 1 times\n",
      "contributing appeared 1 times\n",
      "team appeared 1 times\n",
      "commitment appeared 1 times\n",
      "continuous appeared 1 times\n",
      "learning appeared 1 times\n",
      "expertise appeared 1 times\n",
      "mindset appeared 1 times\n",
      "make appeared 1 times\n",
      "ideal appeared 1 times\n",
      "candidate appeared 1 times\n",
      "internship appeared 1 times\n",
      "available appeared 1 times\n",
      "work appeared 1 times\n",
      "hours appeared 1 times\n",
      "week appeared 1 times\n",
      "weeks appeared 1 times\n",
      "august appeared 1 times\n",
      "eager appeared 1 times\n",
      "contribute appeared 1 times\n",
      "thank appeared 1 times\n",
      "considering appeared 1 times\n",
      "look appeared 1 times\n",
      "forward appeared 1 times\n",
      "opportunity appeared 1 times\n",
      "discuss appeared 1 times\n",
      "goals appeared 1 times\n",
      "sincerely appeared 1 times\n",
      "john appeared 1 times\n",
      "doe appeared 1 times\n",
      "johndoe appeared 1 times\n",
      "gmail appeared 1 times\n",
      "com appeared 1 times\n"
     ]
    }
   ],
   "source": [
    "# Counting the frequency of individual words, storing results in word_freq\n",
    "def get_single_word_frequency(processed_cover_letter):\n",
    "    word_freq = {}  # initializing an empty dictionary called word_freq to store word frequencies\n",
    "    for cover_letter_text in processed_cover_letter:\n",
    "        for word in cover_letter_text.split():\n",
    "            if word not in word_freq:\n",
    "                word_freq[word] = 1\n",
    "            else:\n",
    "                word_freq[word] += 1\n",
    "    return word_freq\n",
    "\n",
    "word_freq = get_single_word_frequency(processed_cover_letter)  # Calling the function to get the word frequencies\n",
    "\n",
    "total_num_words = sum(word_freq.values())\n",
    "print('number of unique words:', len(word_freq))\n",
    "print('total number of word occurrences:', total_num_words)\n",
    "print(\"\")\n",
    "\n",
    "# Calculating and displaying the top 10 most frequently occurring words\n",
    "print(\"\\033[4mAll the words and their frequency:\\033[0m\")\n",
    "\n",
    "for word, freq in sorted(word_freq.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(word, \"appeared\", freq, \"times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b77641",
   "metadata": {},
   "source": [
    "##### Cover letter score grading (addition) Part 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "66d6803d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cover Letter points earned (part 6): 2.7586206896551726 points out of 34 max points\n"
     ]
    }
   ],
   "source": [
    "# Each question for part 6 and 7 are 40/58 points each totalling a combination of 40 points for both sections\n",
    "\n",
    "# Part 6 (34 points max)\n",
    "# Purpose: grading by word pairs\n",
    "\n",
    "# Logic for word pairs and their associated points\n",
    "word_pair_points = {\n",
    "    ('pivotal', 'role'): 40/58,\n",
    "    ('thank', 'you'): 40/58,\n",
    "    ('machine', 'learning'): 40/58,\n",
    "    ('neptune', 'technologies'): 40/58,\n",
    "    ('strong', 'interest'): 40/58,\n",
    "    ('deep', 'understanding'): 40/58,\n",
    "    ('web', 'frameworks'): 40/58,\n",
    "    ('profound', 'understanding'): 40/58,\n",
    "    ('self', 'learner'): 40/58,\n",
    "    ('user', 'friendly'): 40/58,\n",
    "    ('dom', 'manipulation'): 40/58,\n",
    "    ('web', 'applications'): 40/58,\n",
    "    ('version', 'control'): 40/58,\n",
    "    ('test', 'automation'): 40/58,\n",
    "    ('continuous', 'integration'): 40/58,\n",
    "    ('continuous', 'deployment'): 40/58,\n",
    "    ('extensive', 'experience'): 40/58,\n",
    "    ('various', 'domains'): 40/58,\n",
    "    ('personal', 'ventures'): 40/58,\n",
    "    ('software', 'engineering'): 40/58,\n",
    "    ('ruby', 'rails'): 40/58,\n",
    "    ('development', 'skills'): 40/58,\n",
    "    ('database', 'expertise'): 40/58,\n",
    "    ('sql', 'nosql'): 40/58,\n",
    "    ('data', 'driven'): 40/58,\n",
    "    ('enriched', 'experience'): 40/58,\n",
    "    ('containerization', 'technologies'): 40/58,\n",
    "    ('cloud', 'computing'): 40/58,\n",
    "    ('collaboration', 'teamwork'): 40/58,\n",
    "    ('firmly', 'believe'): 40/58,\n",
    "    ('web', 'development'): 40/58,\n",
    "    ('front', 'end'): 40/58,\n",
    "    ('back', 'end'): 40/58,\n",
    "    ('data', 'science'): 40/58\n",
    "}\n",
    "\n",
    "# Initializing total points\n",
    "cover_letter_points_6 = 0\n",
    "\n",
    "# Iterating through the word pairs and their frequencies\n",
    "for pair, freq in pair_freq.items():\n",
    "    # Checking if the pair is in the word_pair_points dictionary\n",
    "    if pair in word_pair_points:\n",
    "        # Adding the associated points to the total\n",
    "        cover_letter_points_6 += word_pair_points[pair]\n",
    "\n",
    "# Printing the total points awarded\n",
    "print(\"Cover Letter points earned (part 6):\", cover_letter_points_6, \"points out of 34 max points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266eb46b",
   "metadata": {},
   "source": [
    "##### Cover letter score grading (addition) Part 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a04a148d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cover Letter points earned (part 7): 6.896551724137932 points out of 24 max points\n"
     ]
    }
   ],
   "source": [
    "# part 7 (24 points max)\n",
    "# Purpose: grading by certains keywords\n",
    "\n",
    "# Initializing a dictionary to store the points for specific words\n",
    "word_points = {\n",
    "    'engineer': 40/58,\n",
    "    'developer': 40/58,\n",
    "    'postgresql': 40/58,\n",
    "    'commitment': 40/58,\n",
    "    'typescript': 40/58,\n",
    "    'redux': 40/58,\n",
    "    'react': 40/58,\n",
    "    'jquery': 40/58,\n",
    "    'git': 40/58,\n",
    "    'restful': 40/58,\n",
    "    'testament': 40/58,\n",
    "    'apis': 40/58,\n",
    "    'storybook': 40/58,\n",
    "    'java': 40/58,\n",
    "    'docker': 40/58,\n",
    "    'azure': 40/58,\n",
    "    'portfolio': 40/58,\n",
    "    'professional': 40/58,\n",
    "    'node': 40/58,\n",
    "    'express': 40/58,\n",
    "    'vue': 40/58,\n",
    "    'cloud': 40/58,\n",
    "    'agile': 40/58,\n",
    "    'tensorflow': 40/58\n",
    "}\n",
    "\n",
    "# Initializing the total points\n",
    "cover_letter_points_7 = 0\n",
    "\n",
    "# Iterating through the words in the processed cover letter\n",
    "for cover_letter_text in processed_cover_letter:\n",
    "    for word in cover_letter_text.split():\n",
    "        # Checking if the word is in the word_points dictionary\n",
    "        if word.lower() in word_points:\n",
    "            # Adding the corresponding points to cover_letter_points_7\n",
    "            cover_letter_points_7 += word_points[word.lower()]\n",
    "\n",
    "# Printing the total points\n",
    "print(\"Cover Letter points earned (part 7):\", cover_letter_points_7, \"points out of 24 max points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6472a7",
   "metadata": {},
   "source": [
    "##### Cover Letter score grading (addition) Total Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b29d3846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cover letter points earned: 6.658739595719383 points out of 40\n"
     ]
    }
   ],
   "source": [
    "# Taking the total points earned for the resume\n",
    "cover_letter_points_earned = (cover_letter_points_6 + cover_letter_points_7)\n",
    "print(\"Cover letter points earned:\", (cover_letter_points_earned/58)*40, \"points out of 40\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b01e69",
   "metadata": {},
   "source": [
    "##### Cover letter score grading (subtraction) part 8 and 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "849de572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cover Letter points deducted (part 8): 0.5 points out of 11.5 points max deduction\n"
     ]
    }
   ],
   "source": [
    "# Part 8\n",
    "# For Word Pairs Point Subtraction\n",
    "\n",
    "# Logic for word pairs and their associated points\n",
    "word_pair_points_8 = {\n",
    "    ('dear', 'sir'): 0.5,\n",
    "    ('dear', 'hiring'): 0.5,\n",
    "    ('i', 'want'): 0.5,\n",
    "    ('i', 'need'): 0.5,\n",
    "    ('detail', 'oriented'): 0.5,\n",
    "    ('team', 'player'): 0.5,\n",
    "    ('go', 'getter'): 0.5,\n",
    "    ('multiple', 'tasks'): 0.5,\n",
    "    ('highly', 'motivated'): 0.5,\n",
    "    ('problem', 'solver'): 0.5,\n",
    "    ('worked', 'on'): 0.5,\n",
    "    ('took', 'orders'): 0.5,\n",
    "    ('pretty', 'good'): 0.5,\n",
    "    ('time', 'management'): 0.5,\n",
    "    ('extra', 'mile'): 0.5,\n",
    "    ('feel', 'free'): 0.5,\n",
    "    ('zero', 'experience'): 0.5,\n",
    "    ('no', 'experience'): 0.5,\n",
    "    ('much', 'experience'): 0.5,\n",
    "    ('innovative', 'thinker'): 0.5,\n",
    "    ('big', 'deal'): 0.5,\n",
    "    ('good', 'deal'): 0.5,\n",
    "    ('great', 'deal'): 0.5\n",
    "}\n",
    "\n",
    "# the more words, the higher the points deduction\n",
    "# 0.5 * 23 = 11.5 points max deduction\n",
    "\n",
    "# Initializing total points\n",
    "cover_letter_points_8 = 0\n",
    "\n",
    "# Iterating through the word pairs and their frequencies\n",
    "for pair, freq in pair_freq.items():\n",
    "    # Checking if the pair is in the word_pair_points_8 dictionary\n",
    "    if pair in word_pair_points_8:\n",
    "        # Adding the associated points to the total\n",
    "        cover_letter_points_8 += word_pair_points_8[pair]\n",
    "\n",
    "# Printing the total points deducted for this section\n",
    "print(\"Cover Letter points deducted (part 8):\", cover_letter_points_8, \"points out of 11.5 points max deduction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2da260c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cover Letter points deducted (part 9): 0.5 points out of 18.5 points max deduction\n"
     ]
    }
   ],
   "source": [
    "# Part 9\n",
    "# For Cover Letter Key words Point Substraction\n",
    "\n",
    "# Initializing a dictionary to store the points for specific words\n",
    "word_points_9 = {\n",
    "    'perfectionist': 0.5,\n",
    "    'challenging': 0.5,\n",
    "    'references': 0.5,\n",
    "    'innovative': 0.5,\n",
    "    'creative': 0.5,\n",
    "    'helped': 0.5,\n",
    "    'sold': 0.5,\n",
    "    'hard': 0.5,\n",
    "    'great': 0.5,\n",
    "    'difficult': 0.5,\n",
    "    'bad': 0.5,\n",
    "    'good': 0.5,\n",
    "    'amazing': 0.5,\n",
    "    'knack': 0.5,\n",
    "    'excellent': 0.5,\n",
    "    'communicator': 0.5,\n",
    "    'soon': 0.5,\n",
    "    'feelings': 0.5,\n",
    "    'very': 0.5,\n",
    "    'bugs': 0.5,\n",
    "    'errors': 0.5,\n",
    "    'probably': 0.5,\n",
    "    'maybe': 0.5,\n",
    "    'overrated': 0.5,\n",
    "    'bills': 0.5,\n",
    "    'big': 0.5,\n",
    "    'lazy': 0.5,\n",
    "    'worries': 0.5,\n",
    "    'worry': 0.5,\n",
    "    'horrible': 0.5,\n",
    "    'salary': 0.5,\n",
    "    'pay': 0.5,\n",
    "    'benefits': 0.5,\n",
    "    'money': 0.5,\n",
    "    'decent': 0.5,\n",
    "    'minimal': 0.5,\n",
    "    'if': 0.5\n",
    "}\n",
    "\n",
    "# the more words, the higher the points deduction\n",
    "# 0.5 * 37 = 18.5 points max deduction\n",
    "\n",
    "# Initializing the total points\n",
    "cover_letter_points_9 = 0\n",
    "\n",
    "# Iterating through the words in the processed cover letter\n",
    "for review_text in processed_cover_letter:\n",
    "    for word in review_text.split():\n",
    "        # Checking if the word is in the word_points_5 dictionary\n",
    "        if word.lower() in word_points_9:\n",
    "            # Adding the corresponding points to cover_letter_points_9\n",
    "            cover_letter_points_9 += word_points_9[word.lower()]\n",
    "\n",
    "# Printing the total points deducted for this section\n",
    "print(\"Cover Letter points deducted (part 9):\", cover_letter_points_9, \"points out of 18.5 points max deduction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440860cf",
   "metadata": {},
   "source": [
    "##### Total Cover Letter Calculation (Points - deduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a289f462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cover letter total (out of 40): 5.66\n"
     ]
    }
   ],
   "source": [
    "cover_letter_percent = \"{:.2f}\".format(((cover_letter_points_earned/58)*40) - (cover_letter_points_8 + cover_letter_points_9))\n",
    "print(\"Cover letter total (out of 40):\", cover_letter_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76206e64",
   "metadata": {},
   "source": [
    "### Form Data Analysis and Grading Section (20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c4512a",
   "metadata": {},
   "source": [
    "##### Removing StopWords, Numerical Digits, Punctuations, Symbols, Extra Spaces, Making Text lowercase and Normalizing and Tokenizing the Text from the form data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "35108141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Adding auxiliary verbs to the stopwords list\n",
    "auxiliary_verbs = ['am', 'is', 'are', 'was', 'were', 'be', 'been', 'being',\n",
    "                   'have', 'has', 'had', 'do', 'does', 'did', 'can', 'could',\n",
    "                   'shall', 'should', 'will', 'would', 'may', 'might', 'must']\n",
    "\n",
    "stop_words.update(auxiliary_verbs)\n",
    "\n",
    "# Initializing a list to store the processed form_data\n",
    "processed_form_data = []\n",
    "\n",
    "# Opening and reading the original file\n",
    "with open(form_data_filepath, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        form_data_text = line.strip()\n",
    "        \n",
    "        # Text cleaning and normalization\n",
    "        for punctuations in ['–', ',', '.', '\"', '!', '?', ':', ';', '-', '(', ')', '[', ']', \"'\", '*', '$', '+','’', \n",
    "                             '_', '{', '}']:\n",
    "            form_data_text = form_data_text.replace(punctuations, ' ')  # Replacing punctuations with spaces\n",
    "            form_data_text = re.sub('\\s+', ' ', form_data_text)  # Removing extra spaces\n",
    "            form_data_text = form_data_text.lower().strip()  # Making text lowercase\n",
    "\n",
    "        # Removing numerical digits\n",
    "        form_data_text = re.sub(r'\\d', '', form_data_text)\n",
    "        \n",
    "        # Tokenizing the cleaned form_data text\n",
    "        words = nltk.word_tokenize(form_data_text)\n",
    "        \n",
    "        # Removing stopwords, including auxiliary verbs\n",
    "        filtered_words = [word for word in words if word not in stop_words]\n",
    "        \n",
    "        # Joining the filtered words back into a sentence\n",
    "        processed_form_data_x = ' '.join(filtered_words)\n",
    "        \n",
    "        processed_form_data.append(processed_form_data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bea86126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'firstname john', 'middlename', 'lastname doe', 'dob', 'gender male', 'phonenumber', 'email johndoe @ gmail com', 'homenumber', 'unitnumber c', 'streetname banana drive', 'city baton blue', 'usstate maryland', 'zipcode', 'degreetype bachelor degree', 'major biological health science', 'uni name university south florida', 'graddate', 'major', 'current employer n/a', 'current job title n/a', 'current job duration n/a', 'previous employers n/a', 'linkinput https //linkedin com', 'linkinput akunnatechstudio com', 'skills n/a', 'certs n/a', 'refs n/a', '']\n"
     ]
    }
   ],
   "source": [
    "# Displaying processed_form_data\n",
    "print(processed_form_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cbe980",
   "metadata": {},
   "source": [
    "##### Combining all lines in processed_form_data into a single line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "024ad442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " firstname john middlename lastname doe dob gender male phonenumber email johndoe @ gmail com homenumber unitnumber c streetname banana drive city baton blue usstate maryland zipcode degreetype bachelor degree major biological health science uni name university south florida graddate major current employer n/a current job title n/a current job duration n/a previous employers n/a linkinput https //linkedin com linkinput akunnatechstudio com skills n/a certs n/a refs n/a \n"
     ]
    }
   ],
   "source": [
    "concatenated_form_data = ' '.join(processed_form_data)\n",
    "print(concatenated_form_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaceca23",
   "metadata": {},
   "source": [
    "##### Form Data Grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4ede53a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Form data score: 16.5\n"
     ]
    }
   ],
   "source": [
    "# starting with 20 points for form data grading\n",
    "starting_score = 20;\n",
    "\n",
    "# Counting the frequency of 'check' and 'N/A' in concatenated_form_data\n",
    "check_count = concatenated_form_data.lower().count(\"check\")\n",
    "na_count = concatenated_form_data.lower().count(\"n/a\")\n",
    "\n",
    "# Subtracting 0.5 * the frequency from starting_score\n",
    "starting_score -= 0.5 * check_count\n",
    "starting_score -= 0.5 * na_count\n",
    "\n",
    "print(\"Form data score:\", starting_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53a6b86",
   "metadata": {},
   "source": [
    "### Applicant's Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d86f8686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applicant's Overall Score: 29.41 %\n",
      "This applicant cannot be considered for this job\n"
     ]
    }
   ],
   "source": [
    "# Calculating the applicant's overall score\n",
    "applicant_percent = \"{:.2f}\".format(float(resume_percent) + float(cover_letter_percent) + float(starting_score))\n",
    "print(\"Applicant's Overall Score:\", applicant_percent, \"%\")\n",
    "\n",
    "# Determining the applicant's evaluation based on the score\n",
    "if 90 <= float(applicant_percent) <= 100:\n",
    "    print(\"This applicant is excellent!\")\n",
    "elif 85 <= float(applicant_percent) < 90:\n",
    "    print(\"This applicant is very good!\")\n",
    "elif 80 <= float(applicant_percent) < 85:\n",
    "    print(\"This applicant is good\")\n",
    "elif 75 <= float(applicant_percent) < 80:\n",
    "    print(\"This applicant is fair\")\n",
    "elif 70 <= float(applicant_percent) < 75:\n",
    "    print(\"This applicant is marginal\")\n",
    "else:\n",
    "    print(\"This applicant cannot be considered for this job\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
